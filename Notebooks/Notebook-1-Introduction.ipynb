{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Introduction to Bayesian Inference\n",
    "When we observed a data set sampled from a larger population, there is variability in the data\n",
    "and uncertainty about the truth. Statistical inference is about applying consistent reasoning to infer the truth when not all the data is available. Bayesian statistics is a particular approach to applying probability to make statistical inferences. We can express our uncertainty as probability and update our subjective beliefs in light of new data or evidence (\\cite{o2004bayesian}). In particular Bayesian inference interprets probability as a measure of believability an individual has about the occurrence of a particular event or the plausibility of a hypothesis. This is in contrast to Frequentist statistics, which assumes that probabilities are the long-run frequency of events from repeated trials.\n",
    "\n",
    "In order to carry out Bayesian inference, we utilise Bayes Rule. To derive Bayes' rule, we start with the definition of conditional probability, which gives us a rule for determining the probability of an event $A$, given the occurrence of another event $B$. \n",
    "\n",
    "\\begin{equation}\n",
    "\t\\begin{aligned}\n",
    "\t\tP(A|B) = \\frac{P(A \\cap B)}{P(B)}\n",
    "\t\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "This states that the probability of $A$ occurring given that $B$ has occurred is equal to the probability that they have both occurred, relative to the probability that  $B$ has occurred. This is a rearrangement of the product or chain rule $P(A\\cap B) = P(B|A)P(A)$. For the joint probability of $A$ and $B$ both occurring we can write:\n",
    "\n",
    "\\begin{equation}\\label{eq:bayes2}\n",
    "\t\\begin{aligned}\n",
    "\t\tP(A\\cap B) = P(A|B)P(B)  \\\\\n",
    "\t\tP(B \\cap A) = P(B|A)P(A) \\\\\n",
    "\t\t\\therefore  P(A|B) = \\frac{P(A)P(B|A)}{P(B)}\n",
    "\t\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "## Bayes' Rule for Bayesian Inference\n",
    "\n",
    "To use Bayes Rule for Bayesian inference we use a modified version of Bayes' rule above that represents the process of stating prior beliefs and updating them in the face of new data. \n",
    "\n",
    "\\begin{equation}\\label{eq:bayes3}\n",
    "\t\\begin{aligned}\n",
    "\t\tp(\\theta|D) = \\frac{p(\\theta)p(D|\\theta)}{P(D)}\n",
    "\t\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- We start with a parameter of interest $\\theta$ which we specify prior distribution for. The prior distribution represents our initial belief about the parameters and can be written as $p(\\theta)$.\n",
    "\n",
    "- Then we must consider the data $D$ and the probability of seeing the data  as generated by a model with parameter $\\theta$. This is expressed as the likelihood.\n",
    "\n",
    "- Lastly the probability of the data $D$ itself is called the marginal likelihood or evidence $P(D)$. This is determined by summing (or integrating) across all possible values of $\\theta$, weighted by our prior beliefs about for each value of $\\theta$.\n",
    "\n",
    "From this we get the posterior distribution $p(\\theta|D)$. This is the updated strength of our beliefs in the possible values of $\\theta$ once the evidence $D$ has been taken into account. \n",
    "\n",
    "## Calculating the Posterior \n",
    "\n",
    "The evidence or marginal likelihood $P(D)$ is formally written as:\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\begin{aligned}\n",
    "\t\tp(D) = \\int p(\\theta) p(D|\\theta)\\ d\\theta\n",
    "\t\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "When we have one or two parameters we can calculate the posterior analytically either by integrating the marginal likelihood or using conjugate priors. In higher parameter spaces it can be difficult to obtain $P(D)$ so the posterior is often simplified to the un-normalised posterior.\n",
    "\\begin{equation}\n",
    "\t\\begin{aligned}\n",
    "\t\tP(\\theta|D) \\propto P(\\theta)P(D|\\theta)\n",
    "\t\\end{aligned}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "# prior \n",
    "\n",
    "# likelihood\n",
    "\n",
    "# posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Methods\n",
    "Without the normalising constant we cannot make the posterior distribution an actual probability distribution (that integrates to one). In Bayesian statistics, the posterior distribution has to be a probability distribution, from which one can derive moments like the posterior mean. \n",
    "When analytical methods are not appropriate, we can instead use simulation methods to generate samples from our posterior distribution for us to make inference from.\n",
    "\n",
    "### MCMC\n",
    "Markov Chain Monte Carlo (MCMC) methods are a class of algorithms for sampling from a probability distribution. When the posterior distribution cannot be solved analytically, we can use MCMC to generate random samples of parameter values drawn from the posterior distribution, $p(\\theta|x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rjags)\n",
    "\n",
    "## model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Summaries\n",
    "\n",
    "The result of running MCMC is instead of having a probability distribution of values of $\\theta$ and corresponding densities, there is a large dataset of sampled parameter values. The more probable regions will contain more data points so we can look at the posterior distribution by plotting a histogram of samples. We can summarise $\\theta$ by calculating descriptive statistics such as the mean, median or standard deviation of the samples. Probabilities like $P(\\theta \\geq 0.5)$ are calculated by counting all the samples with $\\theta \\geq 0.5$ and dividing by the total number of samples. \n",
    "\n",
    "This method works well on more complex problems when we have many parameters. Usually if we wanted to infer two parameters $\\theta_1$ and $\\theta_2$ we would have the joint posterior distribution:\n",
    "\n",
    "$$p(\\theta_1, \\theta_2|D) \\propto p(\\theta_1, \\theta_2)  p(D|\\theta_1, \\theta_2) $$ \n",
    "and inferring the value of $\\theta_1$ on its own would require the marginal posterior distribution for $\\theta_1$ (that is, the posterior distribution for a on its own, not the joint distribution with $\\theta_2$), which we can get by summing over all values of $\\theta_2$:\n",
    "\n",
    "\\begin{equation}\n",
    "\tp(\\theta_1|D) = \\int p(\\theta_1, \\theta_2|D)\\ d\\theta_2\n",
    "\\end{equation}\n",
    "\n",
    "Having posterior samples makes the process of marginalisation much easier as MCMC already returns the marginal distribution of each parameter for if all other parameter were ignored. We can easily plot the distribution or make inference about a single parameter using the marginal samples provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarise posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
